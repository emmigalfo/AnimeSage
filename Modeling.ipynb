{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0b66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e48fd333",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r anime_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a848340",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f5d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Surprise\n",
    "from surprise import Reader, Dataset, SVD, accuracy\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "from surprise.prediction_algorithms import SVD\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73dfd03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data ready for Surprise\n",
    "# With collaborative filtering, only user, item, and rating are needed\n",
    "data = anime_ratings[['user_id', 'MAL_ID', 'rating']]\n",
    "\n",
    "reader = Reader(line_format='user item rating', sep=',')\n",
    "data = Dataset.load_from_df(data, reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "722088a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train test split\n",
    "trainset, testset = train_test_split(data, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c99cbbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.2239\n",
      "RMSE: 3.223900678618706\n"
     ]
    }
   ],
   "source": [
    "# Instatiate svd\n",
    "svd = SVD(n_factors=15, n_epochs=10, lr_all=0.005, reg_all=0.02, random_state=42)\n",
    "\n",
    "# Fit to the training set\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Create predictions\n",
    "predictions = svd.test(testset)\n",
    "\n",
    "# Measure the accuracy of the predictions\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a17a01a",
   "metadata": {},
   "source": [
    "__Insights:__ The baseline model's predictions were 3 points off from the actual ratings. This is a fairly large spread."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8067ccf9",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd2c0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data ready for Surprise\n",
    "# With collaborative filtering, only user, item, and rating are needed\n",
    "data = anime_ratings[['user_id', 'MAL_ID', 'rating']]\n",
    "\n",
    "# Take a sample of data to use in a grid search\n",
    "num_samples = 100000\n",
    "sampled_data = data.sample(n=num_samples, random_state=42)\n",
    "\n",
    "# Instatiate reader and load sampled_data using surprise \n",
    "reader = Reader(line_format='user item rating', sep=',')\n",
    "sampled_data = Dataset.load_from_df(sampled_data, reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c8549a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_factors': [5, 15, 20],\n",
    "    'n_epochs': [5, 10, 25],\n",
    "    'lr_all': [0.002, 0.005, 0.01],\n",
    "    'reg_all': [0.02, 0.04, 0.06]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98836be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cff7b41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:  1.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 3.2304\n",
      "Best Parameters: {'n_factors': 5, 'n_epochs': 25, 'lr_all': 0.01, 'reg_all': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.1min finished\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_factors': [5, 15, 20],\n",
    "    'n_epochs': [5, 10, 25],\n",
    "    'lr_all': [0.002, 0.005, 0.01],\n",
    "    'reg_all': [0.02, 0.04, 0.06]\n",
    "}\n",
    "\n",
    "# Create a 5-fold cross-validation object\n",
    "kf = KFold(n_splits=5, random_state=42)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=5, n_jobs=-1, joblib_verbose=6)\n",
    "\n",
    "# Fit the grid search to the sampled data\n",
    "grid_search.fit(sampled_data)\n",
    "\n",
    "# Print the best RMSE and corresponding hyperparameters\n",
    "print(\"Best RMSE: {:.4f}\".format(grid_search.best_score['rmse']))\n",
    "print(\"Best Parameters:\", grid_search.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56fcca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data ready for Surprise\n",
    "# With collaborative filtering, only user, item, and rating are needed\n",
    "data = anime_ratings[['user_id', 'MAL_ID', 'rating']]\n",
    "\n",
    "# Instatiate reader and load sampled_data using surprise \n",
    "reader = Reader(line_format='user item rating', sep=',')\n",
    "data = Dataset.load_from_df(data, reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aefa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "IOStream.flush timed out\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_factors': [5, 15, 20],\n",
    "    'n_epochs': [5, 10, 25],\n",
    "    'lr_all': [0.002, 0.005, 0.01],\n",
    "    'reg_all': [0.02, 0.04, 0.06]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=5, n_jobs=-1, joblib_verbose=6)\n",
    "\n",
    "# Fit the grid search to the sampled data\n",
    "grid_search.fit(data)\n",
    "\n",
    "# Print the best RMSE and corresponding hyperparameters\n",
    "print(\"Best RMSE: {:.4f}\".format(grid_search.best_score['rmse']))\n",
    "print(\"Best Parameters:\", grid_search.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a406107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
